{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bb2da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rospy\n",
    "import math\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from std_srvs.srv import Empty\n",
    "from gazebo_msgs.msg import LinkStates\n",
    "from std_msgs.msg import Float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e7a9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pubLeftWheelEffort  = rospy.Publisher('/two_wheel_robot/left_wheel_effort_controller/command', Float64, queue_size=1)\n",
    "pubRightWheelEffort = rospy.Publisher('/two_wheel_robot/right_wheel_effort_controller/command', Float64, queue_size=1)\n",
    "\n",
    "reset_world = rospy.ServiceProxy('/gazebo/reset_world', Empty)\n",
    "unpause = rospy.ServiceProxy('/gazebo/unpause_physics', Empty)\n",
    "pause = rospy.ServiceProxy('/gazebo/pause_physics', Empty)\n",
    "\n",
    "rospy.init_node('cartpole_control_script')\n",
    "rate = rospy.Rate(120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a83e0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### DQN from minimalRL ########\n",
    "import collections\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "#Hyperparameters\n",
    "learning_rate = 0.005\n",
    "gamma         = 0.98\n",
    "buffer_limit  = 50000\n",
    "batch_size    = 32\n",
    "\n",
    "class ReplayBuffer():\n",
    "    def __init__(self):\n",
    "        self.buffer = collections.deque(maxlen=buffer_limit)\n",
    "    \n",
    "    def put(self, transition):\n",
    "        self.buffer.append(transition)\n",
    "    \n",
    "    def sample(self, n):\n",
    "        mini_batch = random.sample(self.buffer, n)\n",
    "        s_lst, a_lst, r_lst, s_prime_lst, done_mask_lst = [], [], [], [], []\n",
    "        \n",
    "        for transition in mini_batch:\n",
    "            s, a, r, s_prime, done_mask = transition\n",
    "            s_lst.append(s)\n",
    "            a_lst.append([a])\n",
    "            r_lst.append([r])\n",
    "            s_prime_lst.append(s_prime)\n",
    "            done_mask_lst.append([done_mask])\n",
    "\n",
    "        return torch.tensor(s_lst, dtype=torch.float), torch.tensor(a_lst), \\\n",
    "               torch.tensor(r_lst), torch.tensor(s_prime_lst, dtype=torch.float), \\\n",
    "               torch.tensor(done_mask_lst)\n",
    "    \n",
    "    def size(self):\n",
    "        return len(self.buffer)\n",
    "\n",
    "class Qnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Qnet, self).__init__()\n",
    "        self.fc1 = nn.Linear(4, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "      \n",
    "    def sample_action(self, obs, epsilon):\n",
    "        out = self.forward(obs)\n",
    "        coin = random.random()\n",
    "        if coin < epsilon:\n",
    "            return random.randint(0,1)\n",
    "        else : \n",
    "            return out.argmax().item()\n",
    "            \n",
    "def train(q, q_target, memory, optimizer):\n",
    "    for i in range(10):\n",
    "        s,a,r,s_prime,done_mask = memory.sample(batch_size)\n",
    "\n",
    "        q_out = q(s)\n",
    "        q_a = q_out.gather(1,a)\n",
    "        max_q_prime = q_target(s_prime).max(1)[0].unsqueeze(1)\n",
    "        target = r + gamma * max_q_prime * done_mask\n",
    "        loss = F.smooth_l1_loss(q_a, target)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "####### END of DQN from minimalRL ########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74287c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RobotState(object):\n",
    "    def __init__(self):\n",
    "        self.body_x = 0.0\n",
    "        self.body_x_dot = 0.0\n",
    "        self.body_theta = 0.0\n",
    "        self.body_theta_dot = 0.0\n",
    "        self.robot_state = [self.body_x, self.body_x_dot, self.body_theta, self.body_theta_dot]\n",
    "        \n",
    "        self.data = None\n",
    "\n",
    "        self.theta_threshold = 0.21\n",
    "        self.x_threshold = 0.4\n",
    "\n",
    "        self.current_effort = 0.0\n",
    "        self.done = False\n",
    "\n",
    "\n",
    "robot_state = RobotState()\n",
    "\n",
    "def set_robot_state():\n",
    "    robot_state.robot_state = [robot_state.body_x, robot_state.body_x_dot, robot_state.body_theta, robot_state.body_theta_dot]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b813c6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset():\n",
    "    rospy.wait_for_service('/gazebo/reset_world')\n",
    "    try:\n",
    "        reset_world()\n",
    "    except (rospy.ServiceException) as e:\n",
    "        print ('reset_world failed!')\n",
    "\n",
    "    rospy.wait_for_service('/gazebo/pause_physics')\n",
    "    try:\n",
    "        pause()\n",
    "    except (rospy.ServiceException) as e:\n",
    "        print ('rospause failed!')\n",
    "\n",
    "    set_robot_state()\n",
    "    robot_state.current_effort = 0\n",
    "    robot_state.done = False\n",
    "    # print ('called reset()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15be88e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_action(action):\n",
    "    rospy.wait_for_service('/gazebo/unpause_physics')\n",
    "    try:\n",
    "        unpause()\n",
    "    except (rospy.ServiceException) as e:\n",
    "        print ('/gazebo/pause_physics service call failed')\n",
    "\n",
    "    if action == 1:\n",
    "        robot_state.current_effort = robot_state.current_effort + 0.001\n",
    "    else:\n",
    "        robot_state.current_effort = robot_state.current_effort - 0.001\n",
    "\n",
    "    pubLeftWheelEffort.publish(robot_state.current_effort)\n",
    "    pubRightWheelEffort.publish(robot_state.current_effort)\n",
    "    \n",
    "    if robot_state.data == None:\n",
    "        while robot_state.data is None:\n",
    "            try:\n",
    "                robot_state.data = rospy.wait_for_message('/gazebo/link_states', LinkStates, timeout=5)\n",
    "            except:\n",
    "                print ('Error getting /gazebo/link_states data.')\n",
    "\n",
    "    robot_state.data = None\n",
    "\n",
    "    set_robot_state()\n",
    "\n",
    "    if robot_state.body_x < -robot_state.x_threshold or robot_state.body_x > robot_state.x_threshold \\\n",
    "            or robot_state.body_theta > robot_state.theta_threshold \\\n",
    "            or robot_state.body_theta < -robot_state.theta_threshold:\n",
    "       \n",
    "        robot_state.done = True\n",
    "        reward = -10\n",
    "\n",
    "    else:\n",
    "        robot_state.done = False\n",
    "        reward = 1\n",
    "\n",
    "    return reward, robot_state.done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7da9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euler_from_quaternion(x, y, z, w):\n",
    "        t0 = +2.0 * (w * x + y * z)\n",
    "        t1 = +1.0 - 2.0 * (x * x + y * y)\n",
    "        roll_x = math.atan2(t0, t1)\n",
    "     \n",
    "        t2 = +2.0 * (w * y - z * x)\n",
    "        t2 = +1.0 if t2 > +1.0 else t2\n",
    "        t2 = -1.0 if t2 < -1.0 else t2\n",
    "        pitch_y = math.asin(t2)\n",
    "     \n",
    "        t3 = +2.0 * (w * z + x * y)\n",
    "        t4 = +1.0 - 2.0 * (y * y + z * z)\n",
    "        yaw_z = math.atan2(t3, t4)\n",
    "     \n",
    "        return roll_x, pitch_y, yaw_z # in radians\n",
    "\n",
    "\n",
    "def callbackLinkStates(data):\n",
    "    robot_state.body_x = data.pose[2].position.x\n",
    "    robot_state.body_x_dot = data.twist[2].linear.x\n",
    "    \n",
    "    quat_x = data.pose[2].orientation.x\n",
    "    quat_y = data.pose[2].orientation.y\n",
    "    quat_z = data.pose[2].orientation.z\n",
    "    quat_w = data.pose[2].orientation.w\n",
    "    roll_x, pitch_y, yaw_z = euler_from_quaternion(quat_x, quat_y, quat_z, quat_w)\n",
    "    robot_state.body_theta = pitch_y # in radian\n",
    "    robot_state.body_theta_dot = data.twist[2].angular.y  # in radian per second\n",
    "\n",
    "    set_robot_state()\n",
    "    # print ('DATA :'), data\n",
    "\n",
    "def listener():\n",
    "    print ('listener')\n",
    "    rospy.Subscriber(\"/gazebo/link_states\", LinkStates, callbackLinkStates) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94600581",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# main()\n",
    "listener()\n",
    "\n",
    "q = Qnet()\n",
    "q_target = Qnet()\n",
    "q_target.load_state_dict(q.state_dict())\n",
    "memory = ReplayBuffer()\n",
    "\n",
    "print_interval = 20\n",
    "score = 0.0  \n",
    "optimizer = optim.Adam(q.parameters(), lr=learning_rate)\n",
    "\n",
    "for n_epi in range(10000):\n",
    "    epsilon = max(0.01, 0.08 - 0.01*(n_epi/200)) #Linear annealing from 8% to 1%\n",
    "    reset()\n",
    "    take_action(random.randint(0,1))\n",
    "    \n",
    "    s = np.asarray(robot_state.robot_state)\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        a = q.sample_action(torch.from_numpy(s).float(), epsilon)      \n",
    "        r, done = take_action(a)\n",
    "        print(\"a: %d, r: %d, robot_state: %.3f, %.3f, %.3f, %.3f\" % (a, r, robot_state.body_x, robot_state.body_x_dot, robot_state.body_theta, robot_state.body_theta_dot))\n",
    "        time.sleep(0.1)\n",
    "        s_prime = np.asarray(robot_state.robot_state)\n",
    "\n",
    "        done_mask = 0.0 if done else 1.0\n",
    "        memory.put((s,a,r/100.0,s_prime, done_mask))\n",
    "        s = s_prime\n",
    "\n",
    "        score += r\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    if memory.size() > 2000:\n",
    "        train(q, q_target, memory, optimizer)\n",
    "\n",
    "    if n_epi%print_interval == 0 and n_epi != 0:\n",
    "        q_target.load_state_dict(q.state_dict())\n",
    "        print(\"n_episode :{}, score : {:.1f}, n_buffer : {}, eps : {:.1f}%\".format(\n",
    "            n_epi, score/print_interval, memory.size(), epsilon*100))\n",
    "        score = 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2efad7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
